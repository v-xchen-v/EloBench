{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=r'../results/google_quora_alpaca_10629_test2/battle_records.csv'\n",
    "import sys, os\n",
    "sys.path.append('/elo_bench')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(filepath)\n",
    "columns_to_inclusive = ['model_a', 'model_b', 'winner']\n",
    "data = df[columns_to_inclusive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elo_rating.rating_helper import get_elo_results_from_battles_data\n",
    "ARENA_K = 4\n",
    "elo_result = get_elo_results_from_battles_data(data, K=ARENA_K)\n",
    "data_no_ties = data[data['winner'].str.contains('tie', na=False) == False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bootstrap: 100%|██████████| 1000/1000 [00:32<00:00, 30.54it/s]\n"
     ]
    }
   ],
   "source": [
    "from elo_rating.rating_helper import get_bootstrap_medium_elo\n",
    "elo_result = get_bootstrap_medium_elo(data, ARENA_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>elo_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>1148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meta-llama/Llama-2-70b-chat-hf</td>\n",
       "      <td>1077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meta-llama/Llama-2-13b-chat-hf</td>\n",
       "      <td>1068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xwin-LM/Xwin-LM-13B-V0.1</td>\n",
       "      <td>1056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Xwin-LM/Xwin-LM-7B-V0.1</td>\n",
       "      <td>1042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lmsys/vicuna-33b-v1.3</td>\n",
       "      <td>1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpt-35-turbo</td>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lmsys/vicuna-13b-v1.5</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lmsys/vicuna-7b-v1.5</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chavinlo/alpaca-native</td>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>chavinlo/alpaca-13b</td>\n",
       "      <td>796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WizardLM/WizardLM-7B-V1.0</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             model  elo_rating\n",
       "0                      gpt-4-turbo        1148\n",
       "1   meta-llama/Llama-2-70b-chat-hf        1077\n",
       "2   meta-llama/Llama-2-13b-chat-hf        1068\n",
       "3    meta-llama/Llama-2-7b-chat-hf        1057\n",
       "4         Xwin-LM/Xwin-LM-13B-V0.1        1056\n",
       "5          Xwin-LM/Xwin-LM-7B-V0.1        1042\n",
       "6            lmsys/vicuna-33b-v1.3        1037\n",
       "7                     gpt-35-turbo        1025\n",
       "8            lmsys/vicuna-13b-v1.5        1004\n",
       "9             lmsys/vicuna-7b-v1.5        1001\n",
       "10          chavinlo/alpaca-native         903\n",
       "11             chavinlo/alpaca-13b         796\n",
       "12       WizardLM/WizardLM-7B-V1.0         784"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elo_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/conda/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from elo_rating.rating_evaluator import compute_acutal_winrate\n",
    "acutal_winrate = compute_acutal_winrate(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model_a</th>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <th>meta-llama/Llama-2-70b-chat-hf</th>\n",
       "      <th>meta-llama/Llama-2-13b-chat-hf</th>\n",
       "      <th>meta-llama/Llama-2-7b-chat-hf</th>\n",
       "      <th>Xwin-LM/Xwin-LM-13B-V0.1</th>\n",
       "      <th>Xwin-LM/Xwin-LM-7B-V0.1</th>\n",
       "      <th>lmsys/vicuna-33b-v1.3</th>\n",
       "      <th>gpt-35-turbo</th>\n",
       "      <th>lmsys/vicuna-13b-v1.5</th>\n",
       "      <th>lmsys/vicuna-7b-v1.5</th>\n",
       "      <th>chavinlo/alpaca-native</th>\n",
       "      <th>chavinlo/alpaca-13b</th>\n",
       "      <th>WizardLM/WizardLM-7B-V1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_b</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728155</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.708738</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.772277</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.723810</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.896226</td>\n",
       "      <td>0.912621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-70b-chat-hf</th>\n",
       "      <td>0.271845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.534653</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.701923</td>\n",
       "      <td>0.699029</td>\n",
       "      <td>0.673267</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.871287</td>\n",
       "      <td>0.910891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-13b-chat-hf</th>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.693069</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.920792</td>\n",
       "      <td>0.913462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-chat-hf</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.574257</td>\n",
       "      <td>0.663462</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.871287</td>\n",
       "      <td>0.826923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xwin-LM/Xwin-LM-13B-V0.1</th>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.584158</td>\n",
       "      <td>0.528846</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.575472</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.792079</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.891089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xwin-LM/Xwin-LM-7B-V0.1</th>\n",
       "      <td>0.291262</td>\n",
       "      <td>0.465347</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.415842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.578431</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.782178</td>\n",
       "      <td>0.932039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lmsys/vicuna-33b-v1.3</th>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.471154</td>\n",
       "      <td>0.495050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.637255</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-35-turbo</th>\n",
       "      <td>0.227723</td>\n",
       "      <td>0.298077</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.421569</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.495050</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.905660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lmsys/vicuna-13b-v1.5</th>\n",
       "      <td>0.158416</td>\n",
       "      <td>0.300971</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.425743</td>\n",
       "      <td>0.424528</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.495050</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.834951</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lmsys/vicuna-7b-v1.5</th>\n",
       "      <td>0.276190</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>0.306931</td>\n",
       "      <td>0.336538</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.362745</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.902913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chavinlo/alpaca-native</th>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.140187</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.186916</td>\n",
       "      <td>0.207921</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.796117</td>\n",
       "      <td>0.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chavinlo/alpaca-13b</th>\n",
       "      <td>0.103774</td>\n",
       "      <td>0.128713</td>\n",
       "      <td>0.079208</td>\n",
       "      <td>0.128713</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.217822</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.165049</td>\n",
       "      <td>0.126214</td>\n",
       "      <td>0.203883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WizardLM/WizardLM-7B-V1.0</th>\n",
       "      <td>0.087379</td>\n",
       "      <td>0.089109</td>\n",
       "      <td>0.086538</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.108911</td>\n",
       "      <td>0.067961</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.097087</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model_a                         gpt-4-turbo  meta-llama/Llama-2-70b-chat-hf  \\\n",
       "model_b                                                                       \n",
       "gpt-4-turbo                             NaN                        0.728155   \n",
       "meta-llama/Llama-2-70b-chat-hf     0.271845                             NaN   \n",
       "meta-llama/Llama-2-13b-chat-hf     0.320000                        0.410000   \n",
       "meta-llama/Llama-2-7b-chat-hf      0.200000                        0.441176   \n",
       "Xwin-LM/Xwin-LM-13B-V0.1           0.330000                        0.510000   \n",
       "Xwin-LM/Xwin-LM-7B-V0.1            0.291262                        0.465347   \n",
       "lmsys/vicuna-33b-v1.3              0.310000                        0.509804   \n",
       "gpt-35-turbo                       0.227723                        0.298077   \n",
       "lmsys/vicuna-13b-v1.5              0.158416                        0.300971   \n",
       "lmsys/vicuna-7b-v1.5               0.276190                        0.326733   \n",
       "chavinlo/alpaca-native             0.150000                        0.140187   \n",
       "chavinlo/alpaca-13b                0.103774                        0.128713   \n",
       "WizardLM/WizardLM-7B-V1.0          0.087379                        0.089109   \n",
       "\n",
       "model_a                         meta-llama/Llama-2-13b-chat-hf  \\\n",
       "model_b                                                          \n",
       "gpt-4-turbo                                           0.680000   \n",
       "meta-llama/Llama-2-70b-chat-hf                        0.590000   \n",
       "meta-llama/Llama-2-13b-chat-hf                             NaN   \n",
       "meta-llama/Llama-2-7b-chat-hf                         0.480000   \n",
       "Xwin-LM/Xwin-LM-13B-V0.1                              0.450000   \n",
       "Xwin-LM/Xwin-LM-7B-V0.1                               0.392157   \n",
       "lmsys/vicuna-33b-v1.3                                 0.323529   \n",
       "gpt-35-turbo                                          0.420000   \n",
       "lmsys/vicuna-13b-v1.5                                 0.411765   \n",
       "lmsys/vicuna-7b-v1.5                                  0.306931   \n",
       "chavinlo/alpaca-native                                0.270000   \n",
       "chavinlo/alpaca-13b                                   0.079208   \n",
       "WizardLM/WizardLM-7B-V1.0                             0.086538   \n",
       "\n",
       "model_a                         meta-llama/Llama-2-7b-chat-hf  \\\n",
       "model_b                                                         \n",
       "gpt-4-turbo                                          0.800000   \n",
       "meta-llama/Llama-2-70b-chat-hf                       0.558824   \n",
       "meta-llama/Llama-2-13b-chat-hf                       0.520000   \n",
       "meta-llama/Llama-2-7b-chat-hf                             NaN   \n",
       "Xwin-LM/Xwin-LM-13B-V0.1                             0.490000   \n",
       "Xwin-LM/Xwin-LM-7B-V0.1                              0.420000   \n",
       "lmsys/vicuna-33b-v1.3                                0.371429   \n",
       "gpt-35-turbo                                         0.392157   \n",
       "lmsys/vicuna-13b-v1.5                                0.425743   \n",
       "lmsys/vicuna-7b-v1.5                                 0.336538   \n",
       "chavinlo/alpaca-native                               0.186916   \n",
       "chavinlo/alpaca-13b                                  0.128713   \n",
       "WizardLM/WizardLM-7B-V1.0                            0.173077   \n",
       "\n",
       "model_a                         Xwin-LM/Xwin-LM-13B-V0.1  \\\n",
       "model_b                                                    \n",
       "gpt-4-turbo                                     0.670000   \n",
       "meta-llama/Llama-2-70b-chat-hf                  0.490000   \n",
       "meta-llama/Llama-2-13b-chat-hf                  0.550000   \n",
       "meta-llama/Llama-2-7b-chat-hf                   0.510000   \n",
       "Xwin-LM/Xwin-LM-13B-V0.1                             NaN   \n",
       "Xwin-LM/Xwin-LM-7B-V0.1                         0.415842   \n",
       "lmsys/vicuna-33b-v1.3                           0.471154   \n",
       "gpt-35-turbo                                    0.500000   \n",
       "lmsys/vicuna-13b-v1.5                           0.424528   \n",
       "lmsys/vicuna-7b-v1.5                            0.441176   \n",
       "chavinlo/alpaca-native                          0.207921   \n",
       "chavinlo/alpaca-13b                             0.056604   \n",
       "WizardLM/WizardLM-7B-V1.0                       0.108911   \n",
       "\n",
       "model_a                         Xwin-LM/Xwin-LM-7B-V0.1  \\\n",
       "model_b                                                   \n",
       "gpt-4-turbo                                    0.708738   \n",
       "meta-llama/Llama-2-70b-chat-hf                 0.534653   \n",
       "meta-llama/Llama-2-13b-chat-hf                 0.607843   \n",
       "meta-llama/Llama-2-7b-chat-hf                  0.580000   \n",
       "Xwin-LM/Xwin-LM-13B-V0.1                       0.584158   \n",
       "Xwin-LM/Xwin-LM-7B-V0.1                             NaN   \n",
       "lmsys/vicuna-33b-v1.3                          0.495050   \n",
       "gpt-35-turbo                                   0.421569   \n",
       "lmsys/vicuna-13b-v1.5                          0.350000   \n",
       "lmsys/vicuna-7b-v1.5                           0.313725   \n",
       "chavinlo/alpaca-native                         0.238095   \n",
       "chavinlo/alpaca-13b                            0.217822   \n",
       "WizardLM/WizardLM-7B-V1.0                      0.067961   \n",
       "\n",
       "model_a                         lmsys/vicuna-33b-v1.3  gpt-35-turbo  \\\n",
       "model_b                                                               \n",
       "gpt-4-turbo                                  0.690000      0.772277   \n",
       "meta-llama/Llama-2-70b-chat-hf               0.490196      0.701923   \n",
       "meta-llama/Llama-2-13b-chat-hf               0.676471      0.580000   \n",
       "meta-llama/Llama-2-7b-chat-hf                0.628571      0.607843   \n",
       "Xwin-LM/Xwin-LM-13B-V0.1                     0.528846      0.500000   \n",
       "Xwin-LM/Xwin-LM-7B-V0.1                      0.504950      0.578431   \n",
       "lmsys/vicuna-33b-v1.3                             NaN      0.480000   \n",
       "gpt-35-turbo                                 0.520000           NaN   \n",
       "lmsys/vicuna-13b-v1.5                        0.411765      0.490196   \n",
       "lmsys/vicuna-7b-v1.5                         0.362745      0.504950   \n",
       "chavinlo/alpaca-native                       0.240000      0.215686   \n",
       "chavinlo/alpaca-13b                          0.070000      0.040000   \n",
       "WizardLM/WizardLM-7B-V1.0                    0.160000      0.094340   \n",
       "\n",
       "model_a                         lmsys/vicuna-13b-v1.5  lmsys/vicuna-7b-v1.5  \\\n",
       "model_b                                                                       \n",
       "gpt-4-turbo                                  0.841584              0.723810   \n",
       "meta-llama/Llama-2-70b-chat-hf               0.699029              0.673267   \n",
       "meta-llama/Llama-2-13b-chat-hf               0.588235              0.693069   \n",
       "meta-llama/Llama-2-7b-chat-hf                0.574257              0.663462   \n",
       "Xwin-LM/Xwin-LM-13B-V0.1                     0.575472              0.558824   \n",
       "Xwin-LM/Xwin-LM-7B-V0.1                      0.650000              0.686275   \n",
       "lmsys/vicuna-33b-v1.3                        0.588235              0.637255   \n",
       "gpt-35-turbo                                 0.509804              0.495050   \n",
       "lmsys/vicuna-13b-v1.5                             NaN              0.495050   \n",
       "lmsys/vicuna-7b-v1.5                         0.504950                   NaN   \n",
       "chavinlo/alpaca-native                       0.250000              0.294118   \n",
       "chavinlo/alpaca-13b                          0.165049              0.126214   \n",
       "WizardLM/WizardLM-7B-V1.0                    0.125000              0.097087   \n",
       "\n",
       "model_a                         chavinlo/alpaca-native  chavinlo/alpaca-13b  \\\n",
       "model_b                                                                       \n",
       "gpt-4-turbo                                   0.850000             0.896226   \n",
       "meta-llama/Llama-2-70b-chat-hf                0.859813             0.871287   \n",
       "meta-llama/Llama-2-13b-chat-hf                0.730000             0.920792   \n",
       "meta-llama/Llama-2-7b-chat-hf                 0.813084             0.871287   \n",
       "Xwin-LM/Xwin-LM-13B-V0.1                      0.792079             0.943396   \n",
       "Xwin-LM/Xwin-LM-7B-V0.1                       0.761905             0.782178   \n",
       "lmsys/vicuna-33b-v1.3                         0.760000             0.930000   \n",
       "gpt-35-turbo                                  0.784314             0.960000   \n",
       "lmsys/vicuna-13b-v1.5                         0.750000             0.834951   \n",
       "lmsys/vicuna-7b-v1.5                          0.705882             0.873786   \n",
       "chavinlo/alpaca-native                             NaN             0.796117   \n",
       "chavinlo/alpaca-13b                           0.203883                  NaN   \n",
       "WizardLM/WizardLM-7B-V1.0                     0.170000             0.470000   \n",
       "\n",
       "model_a                         WizardLM/WizardLM-7B-V1.0  \n",
       "model_b                                                    \n",
       "gpt-4-turbo                                      0.912621  \n",
       "meta-llama/Llama-2-70b-chat-hf                   0.910891  \n",
       "meta-llama/Llama-2-13b-chat-hf                   0.913462  \n",
       "meta-llama/Llama-2-7b-chat-hf                    0.826923  \n",
       "Xwin-LM/Xwin-LM-13B-V0.1                         0.891089  \n",
       "Xwin-LM/Xwin-LM-7B-V0.1                          0.932039  \n",
       "lmsys/vicuna-33b-v1.3                            0.840000  \n",
       "gpt-35-turbo                                     0.905660  \n",
       "lmsys/vicuna-13b-v1.5                            0.875000  \n",
       "lmsys/vicuna-7b-v1.5                             0.902913  \n",
       "chavinlo/alpaca-native                           0.830000  \n",
       "chavinlo/alpaca-13b                              0.530000  \n",
       "WizardLM/WizardLM-7B-V1.0                             NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acutal_winrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rank for each column\n",
    "acutal_winrate_rank = acutal_winrate.rank(ascending=False, method='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model_a</th>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <th>meta-llama/Llama-2-70b-chat-hf</th>\n",
       "      <th>meta-llama/Llama-2-13b-chat-hf</th>\n",
       "      <th>meta-llama/Llama-2-7b-chat-hf</th>\n",
       "      <th>Xwin-LM/Xwin-LM-13B-V0.1</th>\n",
       "      <th>Xwin-LM/Xwin-LM-7B-V0.1</th>\n",
       "      <th>lmsys/vicuna-33b-v1.3</th>\n",
       "      <th>gpt-35-turbo</th>\n",
       "      <th>lmsys/vicuna-13b-v1.5</th>\n",
       "      <th>lmsys/vicuna-7b-v1.5</th>\n",
       "      <th>chavinlo/alpaca-native</th>\n",
       "      <th>chavinlo/alpaca-13b</th>\n",
       "      <th>WizardLM/WizardLM-7B-V1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_b</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-70b-chat-hf</th>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-13b-chat-hf</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-7b-chat-hf</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xwin-LM/Xwin-LM-13B-V0.1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xwin-LM/Xwin-LM-7B-V0.1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lmsys/vicuna-33b-v1.3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-35-turbo</th>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lmsys/vicuna-13b-v1.5</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lmsys/vicuna-7b-v1.5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chavinlo/alpaca-native</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chavinlo/alpaca-13b</th>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WizardLM/WizardLM-7B-V1.0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model_a                         gpt-4-turbo  meta-llama/Llama-2-70b-chat-hf  \\\n",
       "model_b                                                                       \n",
       "gpt-4-turbo                             NaN                             1.0   \n",
       "meta-llama/Llama-2-70b-chat-hf          6.0                             NaN   \n",
       "meta-llama/Llama-2-13b-chat-hf          2.0                             6.0   \n",
       "meta-llama/Llama-2-7b-chat-hf           8.0                             5.0   \n",
       "Xwin-LM/Xwin-LM-13B-V0.1                1.0                             2.0   \n",
       "Xwin-LM/Xwin-LM-7B-V0.1                 4.0                             4.0   \n",
       "lmsys/vicuna-33b-v1.3                   3.0                             3.0   \n",
       "gpt-35-turbo                            7.0                             9.0   \n",
       "lmsys/vicuna-13b-v1.5                   9.0                             8.0   \n",
       "lmsys/vicuna-7b-v1.5                    5.0                             7.0   \n",
       "chavinlo/alpaca-native                 10.0                            10.0   \n",
       "chavinlo/alpaca-13b                    11.0                            11.0   \n",
       "WizardLM/WizardLM-7B-V1.0              12.0                            12.0   \n",
       "\n",
       "model_a                         meta-llama/Llama-2-13b-chat-hf  \\\n",
       "model_b                                                          \n",
       "gpt-4-turbo                                                1.0   \n",
       "meta-llama/Llama-2-70b-chat-hf                             2.0   \n",
       "meta-llama/Llama-2-13b-chat-hf                             NaN   \n",
       "meta-llama/Llama-2-7b-chat-hf                              3.0   \n",
       "Xwin-LM/Xwin-LM-13B-V0.1                                   4.0   \n",
       "Xwin-LM/Xwin-LM-7B-V0.1                                    7.0   \n",
       "lmsys/vicuna-33b-v1.3                                      8.0   \n",
       "gpt-35-turbo                                               5.0   \n",
       "lmsys/vicuna-13b-v1.5                                      6.0   \n",
       "lmsys/vicuna-7b-v1.5                                       9.0   \n",
       "chavinlo/alpaca-native                                    10.0   \n",
       "chavinlo/alpaca-13b                                       12.0   \n",
       "WizardLM/WizardLM-7B-V1.0                                 11.0   \n",
       "\n",
       "model_a                         meta-llama/Llama-2-7b-chat-hf  \\\n",
       "model_b                                                         \n",
       "gpt-4-turbo                                               1.0   \n",
       "meta-llama/Llama-2-70b-chat-hf                            2.0   \n",
       "meta-llama/Llama-2-13b-chat-hf                            3.0   \n",
       "meta-llama/Llama-2-7b-chat-hf                             NaN   \n",
       "Xwin-LM/Xwin-LM-13B-V0.1                                  4.0   \n",
       "Xwin-LM/Xwin-LM-7B-V0.1                                   6.0   \n",
       "lmsys/vicuna-33b-v1.3                                     8.0   \n",
       "gpt-35-turbo                                              7.0   \n",
       "lmsys/vicuna-13b-v1.5                                     5.0   \n",
       "lmsys/vicuna-7b-v1.5                                      9.0   \n",
       "chavinlo/alpaca-native                                   10.0   \n",
       "chavinlo/alpaca-13b                                      12.0   \n",
       "WizardLM/WizardLM-7B-V1.0                                11.0   \n",
       "\n",
       "model_a                         Xwin-LM/Xwin-LM-13B-V0.1  \\\n",
       "model_b                                                    \n",
       "gpt-4-turbo                                          1.0   \n",
       "meta-llama/Llama-2-70b-chat-hf                       5.0   \n",
       "meta-llama/Llama-2-13b-chat-hf                       2.0   \n",
       "meta-llama/Llama-2-7b-chat-hf                        3.0   \n",
       "Xwin-LM/Xwin-LM-13B-V0.1                             NaN   \n",
       "Xwin-LM/Xwin-LM-7B-V0.1                              9.0   \n",
       "lmsys/vicuna-33b-v1.3                                6.0   \n",
       "gpt-35-turbo                                         4.0   \n",
       "lmsys/vicuna-13b-v1.5                                8.0   \n",
       "lmsys/vicuna-7b-v1.5                                 7.0   \n",
       "chavinlo/alpaca-native                              10.0   \n",
       "chavinlo/alpaca-13b                                 12.0   \n",
       "WizardLM/WizardLM-7B-V1.0                           11.0   \n",
       "\n",
       "model_a                         Xwin-LM/Xwin-LM-7B-V0.1  \\\n",
       "model_b                                                   \n",
       "gpt-4-turbo                                         1.0   \n",
       "meta-llama/Llama-2-70b-chat-hf                      5.0   \n",
       "meta-llama/Llama-2-13b-chat-hf                      2.0   \n",
       "meta-llama/Llama-2-7b-chat-hf                       4.0   \n",
       "Xwin-LM/Xwin-LM-13B-V0.1                            3.0   \n",
       "Xwin-LM/Xwin-LM-7B-V0.1                             NaN   \n",
       "lmsys/vicuna-33b-v1.3                               6.0   \n",
       "gpt-35-turbo                                        7.0   \n",
       "lmsys/vicuna-13b-v1.5                               8.0   \n",
       "lmsys/vicuna-7b-v1.5                                9.0   \n",
       "chavinlo/alpaca-native                             10.0   \n",
       "chavinlo/alpaca-13b                                11.0   \n",
       "WizardLM/WizardLM-7B-V1.0                          12.0   \n",
       "\n",
       "model_a                         lmsys/vicuna-33b-v1.3  gpt-35-turbo  \\\n",
       "model_b                                                               \n",
       "gpt-4-turbo                                       1.0           1.0   \n",
       "meta-llama/Llama-2-70b-chat-hf                    7.0           2.0   \n",
       "meta-llama/Llama-2-13b-chat-hf                    2.0           4.0   \n",
       "meta-llama/Llama-2-7b-chat-hf                     3.0           3.0   \n",
       "Xwin-LM/Xwin-LM-13B-V0.1                          4.0           7.0   \n",
       "Xwin-LM/Xwin-LM-7B-V0.1                           6.0           5.0   \n",
       "lmsys/vicuna-33b-v1.3                             NaN           9.0   \n",
       "gpt-35-turbo                                      5.0           NaN   \n",
       "lmsys/vicuna-13b-v1.5                             8.0           8.0   \n",
       "lmsys/vicuna-7b-v1.5                              9.0           6.0   \n",
       "chavinlo/alpaca-native                           10.0          10.0   \n",
       "chavinlo/alpaca-13b                              12.0          12.0   \n",
       "WizardLM/WizardLM-7B-V1.0                        11.0          11.0   \n",
       "\n",
       "model_a                         lmsys/vicuna-13b-v1.5  lmsys/vicuna-7b-v1.5  \\\n",
       "model_b                                                                       \n",
       "gpt-4-turbo                                       1.0                   1.0   \n",
       "meta-llama/Llama-2-70b-chat-hf                    2.0                   4.0   \n",
       "meta-llama/Llama-2-13b-chat-hf                    4.0                   2.0   \n",
       "meta-llama/Llama-2-7b-chat-hf                     7.0                   5.0   \n",
       "Xwin-LM/Xwin-LM-13B-V0.1                          6.0                   7.0   \n",
       "Xwin-LM/Xwin-LM-7B-V0.1                           3.0                   3.0   \n",
       "lmsys/vicuna-33b-v1.3                             4.0                   6.0   \n",
       "gpt-35-turbo                                      8.0                   8.0   \n",
       "lmsys/vicuna-13b-v1.5                             NaN                   8.0   \n",
       "lmsys/vicuna-7b-v1.5                              9.0                   NaN   \n",
       "chavinlo/alpaca-native                           10.0                  10.0   \n",
       "chavinlo/alpaca-13b                              11.0                  11.0   \n",
       "WizardLM/WizardLM-7B-V1.0                        12.0                  12.0   \n",
       "\n",
       "model_a                         chavinlo/alpaca-native  chavinlo/alpaca-13b  \\\n",
       "model_b                                                                       \n",
       "gpt-4-turbo                                        2.0                  5.0   \n",
       "meta-llama/Llama-2-70b-chat-hf                     1.0                  7.0   \n",
       "meta-llama/Llama-2-13b-chat-hf                     9.0                  4.0   \n",
       "meta-llama/Llama-2-7b-chat-hf                      3.0                  7.0   \n",
       "Xwin-LM/Xwin-LM-13B-V0.1                           4.0                  2.0   \n",
       "Xwin-LM/Xwin-LM-7B-V0.1                            6.0                 11.0   \n",
       "lmsys/vicuna-33b-v1.3                              7.0                  3.0   \n",
       "gpt-35-turbo                                       5.0                  1.0   \n",
       "lmsys/vicuna-13b-v1.5                              8.0                  9.0   \n",
       "lmsys/vicuna-7b-v1.5                              10.0                  6.0   \n",
       "chavinlo/alpaca-native                             NaN                 10.0   \n",
       "chavinlo/alpaca-13b                               11.0                  NaN   \n",
       "WizardLM/WizardLM-7B-V1.0                         12.0                 12.0   \n",
       "\n",
       "model_a                         WizardLM/WizardLM-7B-V1.0  \n",
       "model_b                                                    \n",
       "gpt-4-turbo                                           3.0  \n",
       "meta-llama/Llama-2-70b-chat-hf                        4.0  \n",
       "meta-llama/Llama-2-13b-chat-hf                        2.0  \n",
       "meta-llama/Llama-2-7b-chat-hf                        11.0  \n",
       "Xwin-LM/Xwin-LM-13B-V0.1                              7.0  \n",
       "Xwin-LM/Xwin-LM-7B-V0.1                               1.0  \n",
       "lmsys/vicuna-33b-v1.3                                 9.0  \n",
       "gpt-35-turbo                                          5.0  \n",
       "lmsys/vicuna-13b-v1.5                                 8.0  \n",
       "lmsys/vicuna-7b-v1.5                                  6.0  \n",
       "chavinlo/alpaca-native                               10.0  \n",
       "chavinlo/alpaca-13b                                  12.0  \n",
       "WizardLM/WizardLM-7B-V1.0                             NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acutal_winrate_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "# Flatten the matrix and prepare data for the Sankey diagram\n",
    "source = []\n",
    "target = []\n",
    "value = []\n",
    "for col in acutal_winrate_rank.columns:\n",
    "    for row in acutal_winrate_rank.index:\n",
    "        source.append(row)\n",
    "        target.append(col)\n",
    "        value.append(acutal_winrate_rank.loc[row, col])\n",
    "        \n",
    "# Map each unique model to an integer for the Sankey diagram\n",
    "unique_models = list(set(source + target))\n",
    "model_to_id = {model: i for i, model in enumerate(unique_models)}\n",
    "\n",
    "# Create a Sankey diagram\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node=dict(\n",
    "        pad=15,\n",
    "        thickness=20,\n",
    "        line=dict(color=\"black\", width=0.5),\n",
    "        label=unique_models\n",
    "    ),\n",
    "    link=dict(\n",
    "        source=[model_to_id[s] for s in source], \n",
    "        target=[model_to_id[t] for t in target],\n",
    "        value=value\n",
    "    ))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(\"sankey.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
