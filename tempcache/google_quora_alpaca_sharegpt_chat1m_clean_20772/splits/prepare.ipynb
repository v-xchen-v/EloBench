{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import os, sys\n",
    "sys.path.append(r'/elo_bench')\n",
    "from datamodel import QuestionCollection\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gemini</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>How does the scoring system in Wordle work?</th>\n",
       "      <td>1. **Correct Letter in Correct Position (Green...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Can you explain the popularity of Wordle and why it's so addictive?</th>\n",
       "      <td>1. **Simplicity and Accessibility:**\\n   - Wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What are some tips for beginners trying to master Wordle?</th>\n",
       "      <td>1. **Start with Common Letters:** Begin by gue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is their a way to cheat on Wordle, or is it all about your search skills?</th>\n",
       "      <td>While Wordle is designed to be a game of skill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Can you tell me some interesting facts about Queen Elizabeth that most people don't know?</th>\n",
       "      <td>1. **She's a trained mechanic.** During World ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assume we have a band-limited signal and an ideal sampling function (Dirac Comb) with frequency twice that of the band-limited signal. We know our signal is band-limited because we filtered it with an ideal brick-wall filter with a pass-band equal to the band-width of the signal; thus the signal is strictly band-limited. Using LaTeX to beautify your mathematical expressions, what is the spectrum of the sampled signal from a purely mathematical point of view? I'm not interested in practical or real scenarios.</th>\n",
       "      <td>Let \\(x(t)\\) be the band-limited signal and \\(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>write a grant specific aims page on social determinants of health and endometrial cancer</th>\n",
       "      <td>**Specific Aims**\\n\\n1. **To examine the assoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Please create a meal plan for a family of 4. Two adults and two children. Please ensure we have one meat free day per week. Ensure that meals are quick and easy to prepare.</th>\n",
       "      <td>**Day 1: Meatless Monday**\\n\\n* Breakfast: Oat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Three.js is a 3D library that tries to make it as easy as possible to get 3D content on a webpage</th>\n",
       "      <td>Three.js is a cross-browser JavaScript library...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>How synthetic data can help with data scarcity in public health\\n\\n</th>\n",
       "      <td>1. **Addressing Data Gaps:**\\n   - Synthetic d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20573 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                               gemini\n",
       "question                                                                                             \n",
       "How does the scoring system in Wordle work?         1. **Correct Letter in Correct Position (Green...\n",
       "Can you explain the popularity of Wordle and wh...  1. **Simplicity and Accessibility:**\\n   - Wor...\n",
       "What are some tips for beginners trying to mast...  1. **Start with Common Letters:** Begin by gue...\n",
       "Is their a way to cheat on Wordle, or is it all...  While Wordle is designed to be a game of skill...\n",
       "Can you tell me some interesting facts about Qu...  1. **She's a trained mechanic.** During World ...\n",
       "...                                                                                               ...\n",
       "Assume we have a band-limited signal and an ide...  Let \\(x(t)\\) be the band-limited signal and \\(...\n",
       "write a grant specific aims page on social dete...  **Specific Aims**\\n\\n1. **To examine the assoc...\n",
       "Please create a meal plan for a family of 4. Tw...  **Day 1: Meatless Monday**\\n\\n* Breakfast: Oat...\n",
       "Three.js is a 3D library that tries to make it ...  Three.js is a cross-browser JavaScript library...\n",
       "How synthetic data can help with data scarcity ...  1. **Addressing Data Gaps:**\\n   - Synthetic d...\n",
       "\n",
       "[20573 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"convert gemini answers to the designed format csv\"\"\"\n",
    "if False:\n",
    "    gemini_answers = pd.read_json(r'./gemini_pro_answer_20573_20231228.jsonl', lines=True)\n",
    "\n",
    "    # take 'question' as row index, and 'answer' as cell of ['question', 'gemini']\n",
    "    gemini_answers = gemini_answers.set_index('question')\n",
    "    gemini_answers = gemini_answers.rename(columns={'answer': 'gemini'})\n",
    "    gemini_answers.to_csv(r'./q_and_as gemini.csv')\n",
    "    gemini_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing information in ./q_and_as 2a100.csv...\n",
      "21259 answers for lmsys/vicuna-7b-v1.5\n",
      "21259 answers for gpt-4-turbo\n",
      "21259 answers for gpt-35-turbo\n",
      "21259 answers for lmsys/vicuna-13b-v1.5\n",
      "21259 answers for lmsys/vicuna-33b-v1.3\n",
      "21259 answers for meta-llama/Llama-2-7b-chat-hf\n",
      "21259 answers for meta-llama/Llama-2-13b-chat-hf\n",
      "21259 answers for huggyllama/llama-13b\n",
      "21259 answers for meta-llama/Llama-2-70b-chat-hf\n",
      "21259 answers for tiiuae/falcon-7b-instruct\n",
      "21259 answers for tiiuae/falcon-40b-instruct\n",
      "21259 answers for mosaicml/mpt-7b-chat\n",
      "21259 answers for WizardLM/WizardLM-13B-V1.2\n",
      "21259 answers for Xwin-LM/Xwin-LM-7B-V0.1\n",
      "21259 answers for chavinlo/alpaca-13b\n",
      "21259 answers for WizardLM/WizardLM-7B-V1.0\n",
      "21259 answers for chavinlo/alpaca-native\n",
      "21259 answers for Xwin-LM/Xwin-LM-13B-V0.1\n",
      "21259 answers for mosaicml/mpt-30b-chat\n",
      "21259 answers for huggyllama/llama-7b\n",
      "21259 answers for HuggingFaceH4/zephyr-7b-beta\n",
      "21259 answers for huggyllama/llama-30b\n",
      "Printing information in ./q_and_as 1503.csv...\n",
      "21963 answers for Xwin-LM/Xwin-LM-13B-V0.1\n",
      "21963 answers for Xwin-LM/Xwin-LM-7B-V0.1\n",
      "21963 answers for WizardLM/WizardLM-7B-V1.0\n",
      "21963 answers for WizardLM/WizardLM-13B-V1.2\n",
      "21963 answers for mosaicml/mpt-7b-chat\n",
      "21963 answers for mosaicml/mpt-30b-chat\n",
      "21963 answers for HuggingFaceH4/zephyr-7b-beta\n",
      "Printing information in ./q_and_as 1673.csv...\n",
      "20332 answers for huggyllama/llama-7b\n",
      "20332 answers for huggyllama/llama-13b\n",
      "20332 answers for huggyllama/llama-30b\n",
      "20332 answers for chavinlo/alpaca-native\n",
      "20332 answers for chavinlo/alpaca-13b\n",
      "Printing information in ./q_and_as 1691...\n",
      "21963 answers for HuggingFaceH4/zephyr-7b-beta\n",
      "21963 answers for tiiuae/falcon-7b-instruct\n",
      "Printing information in ./q_and_as gemini.csv...\n",
      "20573 answers for gemini\n",
      "Printing information in ./q_and_as 2a100 split.csv...\n",
      "2314 answers for tiiuae/falcon-40b-instruct\n"
     ]
    }
   ],
   "source": [
    "\"\"\"list csv splits models name with answers count and percentage\"\"\"\n",
    "if True:\n",
    "    split_csv_files = [\n",
    "        r'./q_and_as 2a100.csv',\n",
    "        r'./q_and_as 1503.csv',\n",
    "        r'./q_and_as 1673.csv',\n",
    "        r'./q_and_as 1691', # √\n",
    "        r'./q_and_as gemini.csv', # √\n",
    "        r'./q_and_as 2a100 split.csv'\n",
    "    ]\n",
    "\n",
    "    for split_csv in split_csv_files:\n",
    "        print(f'Printing information in {split_csv}...')\n",
    "        answer_split = pd.read_csv(split_csv, engine='python', keep_default_na=False, na_values=['NaN', 'NULL'])\n",
    "        skip_columns = ['Unnamed: 0', 'question']\n",
    "        models = [x for x in answer_split.columns.tolist() if not x in (skip_columns)]\n",
    "        for model in models:\n",
    "            print(f'{len(answer_split[model].tolist())} answers for {model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG] Removed 48 repeat questions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20772 questions.\n",
      "Printing information in ./q_and_as 2a100.csv...\n",
      "lmsys/vicuna-7b-v1.5\n",
      "gpt-4-turbo\n",
      "gpt-35-turbo\n",
      "lmsys/vicuna-13b-v1.5\n",
      "lmsys/vicuna-33b-v1.3\n",
      "meta-llama/Llama-2-7b-chat-hf\n",
      "meta-llama/Llama-2-13b-chat-hf\n",
      "huggyllama/llama-13b\n",
      "meta-llama/Llama-2-70b-chat-hf\n",
      "tiiuae/falcon-7b-instruct\n",
      "tiiuae/falcon-40b-instruct\n",
      "mosaicml/mpt-7b-chat\n",
      "WizardLM/WizardLM-13B-V1.2\n",
      "Xwin-LM/Xwin-LM-7B-V0.1\n",
      "chavinlo/alpaca-13b\n",
      "WizardLM/WizardLM-7B-V1.0\n",
      "chavinlo/alpaca-native\n",
      "Xwin-LM/Xwin-LM-13B-V0.1\n",
      "mosaicml/mpt-30b-chat\n",
      "huggyllama/llama-7b\n",
      "HuggingFaceH4/zephyr-7b-beta\n",
      "huggyllama/llama-30b\n",
      "Printing information in ./q_and_as 1503.csv...\n",
      "Xwin-LM/Xwin-LM-13B-V0.1\n",
      "Xwin-LM/Xwin-LM-7B-V0.1\n",
      "WizardLM/WizardLM-7B-V1.0\n",
      "WizardLM/WizardLM-13B-V1.2\n",
      "mosaicml/mpt-7b-chat\n",
      "mosaicml/mpt-30b-chat\n",
      "HuggingFaceH4/zephyr-7b-beta\n",
      "Printing information in ./q_and_as 1673.csv...\n",
      "huggyllama/llama-7b\n",
      "huggyllama/llama-13b\n",
      "huggyllama/llama-30b\n",
      "chavinlo/alpaca-native\n",
      "chavinlo/alpaca-13b\n",
      "Printing information in ./q_and_as 1691...\n",
      "HuggingFaceH4/zephyr-7b-beta\n",
      "tiiuae/falcon-7b-instruct\n",
      "Printing information in ./q_and_as gemini.csv...\n",
      "gemini\n",
      "Printing information in ./q_and_as 2a100 split.csv...\n",
      "tiiuae/falcon-40b-instruct\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Merge the answers for dataset\"\"\"\n",
    "dataset_dir = r'/elo_bench/data/google_quora_alpaca_sharegpt_chatlm_clean_20772'\n",
    "questions = QuestionCollection.read_csv(Path(dataset_dir)/'questions.csv').questions\n",
    "question_set = set(questions)\n",
    "\n",
    "print(f'{len(questions)} questions.')\n",
    "\n",
    "split_csv_files = [\n",
    "    r'./q_and_as 2a100.csv',\n",
    "    r'./q_and_as 1503.csv',\n",
    "    r'./q_and_as 1673.csv',\n",
    "    r'./q_and_as 1691', # √\n",
    "    r'./q_and_as gemini.csv', # √\n",
    "    r'./q_and_as 2a100 split.csv'\n",
    "]\n",
    "\n",
    "\n",
    "q_and_as_dict = defaultdict(lambda: defaultdict(str)) #  a_and_as_dict['question']['model']=ans\n",
    "for split_csv in split_csv_files:\n",
    "    print(f'Printing information in {split_csv}...')\n",
    "    answer_split = pd.read_csv(split_csv, keep_default_na=False, na_values=['NaN'], engine='python')\n",
    "    # answer_splits.append(answer_split)\n",
    "    skip_columns = ['Unnamed: 0', 'question']\n",
    "    models = [str(x) for x in answer_split.columns.tolist() if not x in (skip_columns)]\n",
    "    for model in models:\n",
    "        print(model)\n",
    "        for index, row in answer_split.iterrows():\n",
    "            question = row['question']\n",
    "            model_answer = row[model]\n",
    "            # print(f'{question}:{model_answer}')\n",
    "            q_and_as_dict[question][model] = model_answer\n",
    "\n",
    "reformat_matrix = []\n",
    "for question_key, model_answers in q_and_as_dict.items():\n",
    "    if question_key not in question_set:\n",
    "        continue\n",
    "    item = {\n",
    "        'question': question_key,\n",
    "    }\n",
    "    for model_name, ans in model_answers.items():\n",
    "        item[model_name] = ans\n",
    "    \n",
    "    reformat_matrix.append(item)\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame.from_dict(reformat_matrix)\n",
    "df\n",
    "df.to_csv(r'./merge.csv', na_rep='NaN')\n",
    "# from functools import reduce   \n",
    "# df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['question'],\n",
    "#                                             how='outer'), answer_splits).fillna('void')\n",
    "# df_merged = pd.concat(answer_splits, join='inner', keys=['question'], axis=1, ig)\n",
    "\n",
    "# df_merged\n",
    "    # skip_columns = ['Unnamed: 0', 'question']\n",
    "    # models = [x for x in answer_split.columns.tolist() if not x in (skip_columns)]\n",
    "    # for model in models:\n",
    "    #     for _, row in answer_split.iterrows():\n",
    "    #         question = row.index\n",
    "    #         model_answer = row[model]\n",
    "            \n",
    "        # answer = answer_split[model].tolist()\n",
    "        # print(f'{len(answer_split[model].tolist())} answers for {model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing information in ./merge.csv...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split_csv \u001b[38;5;129;01min\u001b[39;00m split_csv_files:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrinting information in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit_csv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     answer_split \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(split_csv, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m'\u001b[39m, keep_default_na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, na_values\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNaN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNULL\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m     skip_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m     models \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m answer_split\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m (skip_columns)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"list csv splits models name with answers count and percentage\"\"\"\n",
    "if True:\n",
    "    split_csv_files = [\n",
    "        r'./merge.csv',\n",
    "    ]\n",
    "\n",
    "    for split_csv in split_csv_files:\n",
    "        print(f'Printing information in {split_csv}...')\n",
    "        answer_split = pd.read_csv(split_csv, engine='python', keep_default_na=False, na_values=['NaN', 'NULL'])\n",
    "        skip_columns = ['Unnamed: 0', 'question']\n",
    "        models = [x for x in answer_split.columns.tolist() if not x in (skip_columns)]\n",
    "        for model in models:\n",
    "            model_answers = answer_split[model]\n",
    "            model_answers = model_answers[~model_answers.isna()]\n",
    "            print(f'{len(model_answers.tolist())} answers for {model}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
